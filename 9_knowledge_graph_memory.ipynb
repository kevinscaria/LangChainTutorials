{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# CONSTANTS\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Knowledge Graph Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    temperature=0,\n",
    "    max_tokens=256,\n",
    "    model='gpt-3.5-turbo-instruct'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an AI model. You will use the content provided in the Relevant Information\n",
      "section to provide answers. If you cannot find the asnwer in the Relevant Information section, reply that you\n",
      "do not know.\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: My name is Kevin\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hello Kevin, it's nice to meet you. Is there anything you would like to talk about?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an AI model. You will use the content provided in the Relevant Information\n",
      "section to provide answers. If you cannot find the asnwer in the Relevant Information section, reply that you\n",
      "do not know.\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: I am an SDE developing software products and am from Seattle, USA\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "That's great! Seattle is known for its thriving tech industry. What kind of software products do you develop?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an AI model. You will use the content provided in the Relevant Information\n",
      "section to provide answers. If you cannot find the asnwer in the Relevant Information section, reply that you\n",
      "do not know.\n",
      "Relevant Information:\n",
      "On Kevin: Kevin is my name. Kevin develops software products. Kevin is from Seattle.\n",
      "\n",
      "Conversation:\n",
      "Human: Where is Kevin from?\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Kevin is from Seattle.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"You are an AI model. You will use the content provided in the Relevant Information\n",
    "section to provide answers. If you cannot find the asnwer in the Relevant Information section, reply that you\n",
    "do not know.\n",
    "Relevant Information:\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI: \n",
    "\"\"\"\n",
    "\n",
    "input_kg_prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"relevant_information\", \"human_input\"]\n",
    ")\n",
    "\n",
    "conversation_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=input_kg_prompt,\n",
    "    memory=ConversationKGMemory(llm=llm),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(conversation_chain.predict(input=\"My name is Kevin\"))\n",
    "print(conversation_chain.predict(input=\"I am an SDE developing software products and am from Seattle, USA\"))\n",
    "print(conversation_chain.predict(input=\"Where is Kevin from?\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
